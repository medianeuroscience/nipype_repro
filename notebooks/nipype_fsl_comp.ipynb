{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Comparing Three-level GLM Results from FSL GUI and Nipype (Docker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>**Execute this notebook outside of the docker container**</mark>\n",
    "\n",
    "In this notebook we explore the outputs of a basic fMRI `Three Level GLM` pipeline in FSL and Nipype. Specifically, we do a quality control check to ensure that results produced by FSL via the Graphical User Interface (GUI) and an FSL worklow in `nipype` produce the same results. Since FSL overwrites outputs and only produces the final results, we used the corresponding `bash` commands to generate stepwise outputs.\n",
    "\n",
    "Importantly, we carry out all analyses in `20.04.2 LTS (Focal Fossa)` as we (and [others](https://www.frontiersin.org/articles/10.3389/fninf.2015.00012/full)) have found that FSL uses mathematical functions based on single-precision floating-point arithmetic whose implementations differ across operating systems. Hence, you cannot expect that your FSL results obtained in a MAC, Windows, or other Linux (e.g., neurodebian) OS will match the results/values that we report here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we use an fMRI dataset that used the Flanker task, which can be downloaded [here](https://openneuro.org/datasets/ds000102/versions/00001). We choose `run-1` of `subject-11` and run the preprocess (1) in FSL GUI (6.0.4), with (2) nipype and (3) FSL (6.0.4) command in the docker. Then we compare results from these three methods step by step.\n",
    "\n",
    "<mark>**Note:**</mark> When run FSL GUI, some output files will be overwritten. Therefore, we use FSL command (outside of the docker, the same system environment as FSL GUI) as an alternative so that we can get the output file and do the comparison at each step. To make sure that FSL command is a good alternative of FSL GUI, we compared the final output of them and found no differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/envs/naturalistic/lib/python3.7/site-packages/nilearn/datasets/__init__.py:90: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  \"Numpy arrays.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from nltools.data import Brain_Data\n",
    "from nilearn.image import get_data, load_img, mean_img\n",
    "from nilearn.plotting import plot_epi\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This preprocessing is conducted within the first-level GLM process. All the comparisons for this part are on `sub-11`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 1: Compare the result of img2float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img2float is the first step in fsl\n",
    "\n",
    "In our **nipype** notebook, this corresponds to the node `img2float`\n",
    "\n",
    "In **fsl**, you can use terminal open a folder and use the command from your fsl logfile, for example:\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslmaths /home/.../flanker/sub-11/func/sub-11_task-flanker_run-1_bold prefiltered_func_data -odt float\n",
    "```\n",
    "\n",
    "then it will generate a file called `prefiltered_func_data.nii.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img2float result from fsl gui\n",
    "file_fsl_gui = '../file4comparison/step_1_gui_prefiltered_func_data.nii.gz'\n",
    "\n",
    "# img2float result from nipype\n",
    "file_fsl_nipype = '../file4comparison/step_1_nipype_bold_dtype.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 238955)\n",
      "(146, 238955)\n"
     ]
    }
   ],
   "source": [
    "brain_fsl_gui = Brain_Data(file_fsl_gui).data\n",
    "print(brain_fsl_gui.shape)\n",
    "brain_fsl_nipype = Brain_Data(file_fsl_nipype).data\n",
    "print(brain_fsl_nipype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 34887430 voxels are different\n"
     ]
    }
   ],
   "source": [
    "diff = brain_fsl_gui - brain_fsl_nipype\n",
    "num_of_non_zeros = np.count_nonzero(diff)\n",
    "print(f\"{num_of_non_zeros} out of {diff.size} voxels are different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 2: Compare the result of extractref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract the middle volume as the reference is the second step in fsl\n",
    "\n",
    "\n",
    "In our **nipype** notebook, this corresponds to the node `extractref`\n",
    "\n",
    "In **fsl**, you can use the command from your fsl logfile, for example:\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslroi prefiltered_func_data example_func 73 1\n",
    "```\n",
    "\n",
    "then it will generate a file called `example_func.nii.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extractref result from fsl gui\n",
    "file_fsl_gui = '../file4comparison/step_2_gui_example_func.nii.gz'\n",
    "\n",
    "# extractref result from nipype\n",
    "file_fsl_nipype = '../file4comparison/step_2_nipype_bold_dtype_roi.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238955,)\n",
      "(238955,)\n"
     ]
    }
   ],
   "source": [
    "brain_fsl_gui = Brain_Data(file_fsl_gui).data\n",
    "print(brain_fsl_gui.shape)\n",
    "brain_fsl_nipype = Brain_Data(file_fsl_nipype).data\n",
    "print(brain_fsl_nipype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 238955 voxels are different\n"
     ]
    }
   ],
   "source": [
    "diff = brain_fsl_gui - brain_fsl_nipype\n",
    "num_of_non_zeros = np.count_nonzero(diff)\n",
    "print(f\"{num_of_non_zeros} out of {diff.size} voxels are different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 3: Compare the result motion correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realign the functional runs to the middle volume of each run\n",
    "\n",
    "In our **nipype** notebook, this corresponds to the node `realign`\n",
    "\n",
    "In **fsl**, you can use the command from your fsl logfile, for example:\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/mcflirt -in prefiltered_func_data -out prefiltered_func_data_mcf -mats -plots -reffile example_func -rmsrel -rmsabs -spline_final\n",
    "```\n",
    "\n",
    "In **fsl GUI**, it corresponds to\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/20402800/125661408-9d6ed3a2-2537-44dd-879f-85181424b171.png)\n",
    "\n",
    "then it will generate a file called `prefiltered_func_data_mcf.nii.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realign result from fsl gui\n",
    "file_fsl_gui = '../file4comparison/step_3_gui_prefiltered_func_data_mcf.nii.gz'\n",
    "\n",
    "# realign result from nipype\n",
    "file_fsl_nipype = '../file4comparison/step_3_nipype_bold_dtype_mcf.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 238955)\n",
      "(146, 238955)\n"
     ]
    }
   ],
   "source": [
    "brain_fsl_gui = Brain_Data(file_fsl_gui).data\n",
    "print(brain_fsl_gui.shape)\n",
    "brain_fsl_nipype = Brain_Data(file_fsl_nipype).data\n",
    "print(brain_fsl_nipype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 34887430 voxels are different\n"
     ]
    }
   ],
   "source": [
    "diff = brain_fsl_gui - brain_fsl_nipype\n",
    "num_of_non_zeros = np.count_nonzero(diff)\n",
    "print(f\"{num_of_non_zeros} out of {diff.size} voxels are different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 4: Compare the result of meanfunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the mean volume of the functional run\n",
    "\n",
    "In our **nipype** notebook, this corresponds to the node `meanfunc`,\n",
    "\n",
    "<mark> Later, FSL applied other transformations on this meanfunc file without renaming, so if executing this step afterwards, results might be different. \n",
    "    Thus, we did not provide files for this step.</mark>\n",
    "\n",
    "\n",
    "In **fsl**, you can use the command from your fsl logfile, for example:\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslmaths prefiltered_func_data_mcf -Tmean mean_func\n",
    "```\n",
    "\n",
    "then it will generate a file called `mask.nii.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meanfunc result from fsl gui\n",
    "file_fsl_gui = '../file4comparison/step_4_gui_mean_func.nii.gz'\n",
    "\n",
    "# meanfunc result from nipype\n",
    "file_fsl_nipype = '../file4comparison/step_4_nipype_bold_dtype_mcf_mean.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238955,)\n",
      "(238955,)\n"
     ]
    }
   ],
   "source": [
    "brain_fsl_gui = Brain_Data(file_fsl_gui).data\n",
    "print(brain_fsl_gui.shape)\n",
    "brain_fsl_nipype = Brain_Data(file_fsl_nipype).data\n",
    "print(brain_fsl_nipype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 238955 voxels are different\n"
     ]
    }
   ],
   "source": [
    "diff = brain_fsl_gui - brain_fsl_nipype\n",
    "num_of_non_zeros = np.count_nonzero(diff)\n",
    "print(f\"{num_of_non_zeros} out of {diff.size} voxels are different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 5: Compare the result of meanfuncmask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strip the skull from the mean functional to generate a mask\n",
    "\n",
    "In our **nipype** notebook, this corresponds to the node `meanfuncmask`,\n",
    "\n",
    "\n",
    "In **fsl**, you can use the command from your fsl logfile, for example:\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/bet2 mean_func mask -f 0.3 -n -m; /usr/local/fsl/bin/immv mask_mask mask\n",
    "```\n",
    "\n",
    "then it will generate a file called `mask.nii.gz`\n",
    "\n",
    "<mark>\n",
    "    Later, FSL applied other transformations on this mask file without renaming, so if executing this step afterwards, results might be different. \n",
    "    Thus, we did not provide files for this step.\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meanfuncmask result from fsl gui\n",
    "file_fsl_gui = '../file4comparison/step_5_gui_mask.nii.gz'\n",
    "\n",
    "# meanfuncmask result from nipype\n",
    "file_fsl_nipype = '../file4comparison/step_5_nipype_bold_dtype_mcf_mean_brain_mask.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/envs/naturalistic/lib/python3.7/site-packages/nilearn/image/resampling.py:527: UserWarning: Casting data from int16 to float32\n",
      "  warnings.warn(\"Casting data from %s to %s\" % (data.dtype.name, aux))\n",
      "/usr/local/miniconda3/envs/naturalistic/lib/python3.7/site-packages/nilearn/image/resampling.py:273: UserWarning: Resampling binary images with continuous or linear interpolation. This might lead to unexpected results. You might consider using nearest interpolation instead.\n",
      "  warnings.warn(\"Resampling binary images with continuous or \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238955,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/envs/naturalistic/lib/python3.7/site-packages/nilearn/image/resampling.py:527: UserWarning: Casting data from int16 to float32\n",
      "  warnings.warn(\"Casting data from %s to %s\" % (data.dtype.name, aux))\n",
      "/usr/local/miniconda3/envs/naturalistic/lib/python3.7/site-packages/nilearn/image/resampling.py:273: UserWarning: Resampling binary images with continuous or linear interpolation. This might lead to unexpected results. You might consider using nearest interpolation instead.\n",
      "  warnings.warn(\"Resampling binary images with continuous or \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238955,)\n"
     ]
    }
   ],
   "source": [
    "brain_fsl_gui = Brain_Data(file_fsl_gui).data\n",
    "print(brain_fsl_gui.shape)\n",
    "brain_fsl_nipype = Brain_Data(file_fsl_nipype).data\n",
    "print(brain_fsl_nipype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 238955 voxels are different\n"
     ]
    }
   ],
   "source": [
    "diff = brain_fsl_gui - brain_fsl_nipype\n",
    "num_of_non_zeros = np.count_nonzero(diff)\n",
    "print(f\"{num_of_non_zeros} out of {diff.size} voxels are different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 6: Compare the result of maskfunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask the functional runs with the extracted mask\n",
    "\n",
    "In our **nipype** notebook, this corresponds to the node `maskfunc`,\n",
    "\n",
    "\n",
    "In **fsl**, you can use the command from your fsl logfile, for example:\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslmaths prefiltered_func_data_mcf -mas mask prefiltered_func_data_bet\n",
    "```\n",
    "\n",
    "In **fsl GUI**, it corresponds to \n",
    "\n",
    "![image](https://user-images.githubusercontent.com/20402800/125662332-488fddef-1950-48b5-af4d-6f3befffd24e.png)\n",
    "\n",
    "then it will generate a file called `prefiltered_func_data_bet.nii.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maskfunc result from fsl gui\n",
    "file_fsl_gui = '../file4comparison/step_6_gui_prefiltered_func_data_bet.nii.gz'\n",
    "\n",
    "# maskfunc result from nipype\n",
    "file_fsl_nipype = '../file4comparison/step_6_nipype_bold_dtype_mcf_bet.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 238955)\n",
      "(146, 238955)\n"
     ]
    }
   ],
   "source": [
    "brain_fsl_gui = Brain_Data(file_fsl_gui).data\n",
    "print(brain_fsl_gui.shape)\n",
    "brain_fsl_nipype = Brain_Data(file_fsl_nipype).data\n",
    "print(brain_fsl_nipype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 34887430 voxels are different\n"
     ]
    }
   ],
   "source": [
    "diff = brain_fsl_gui - brain_fsl_nipype\n",
    "num_of_non_zeros = np.count_nonzero(diff)\n",
    "print(f\"{num_of_non_zeros} out of {diff.size} voxels are different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 7: Compare the result of thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1: Determine the 2nd and 98th percentile intensities of each functional run. It will return two numbers, which will be used in the following step.\n",
    "\n",
    "7.2: Threshold the first run of the functional data at 10% of the 98th percentile\n",
    "\n",
    "In our **nipype** notebook, this corresponds to the node `getthreshold` & `threshold`,\n",
    "\n",
    "\n",
    "In **fsl**, you can use the command from your fsl logfile, for example:\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslstats prefiltered_func_data_bet -p 2 -p 98\n",
    "0.000000 873.492249 (these numbers are for subject-11 run-01)\n",
    "/usr/local/fsl/bin/fslmaths prefiltered_func_data_bet -thr 87.3492249 -Tmin -bin mask -odt char\n",
    "```\n",
    "\n",
    "All steps perform on `mask.nii.gz`\n",
    "\n",
    "<mark>\n",
    "    Later, FSL applied other transformations on this mask file without renaming, so if executing this step afterwards, results might be different. \n",
    "    Thus, we did not provide files for this step.\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 8: Compare the result of dilate the mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the threshold from **Step 7** to dilate the mask\n",
    "\n",
    "In our **nipype** notebook, this corresponds to the node `dilatemask`,\n",
    "\n",
    "\n",
    "In **fsl**, you can use the command from your fsl logfile, for example:\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslmaths mask -dilF mask\n",
    "```\n",
    "\n",
    "All steps perform on `mask.nii.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dilatemask result from fsl gui\n",
    "file_fsl_gui = '../file4comparison/step_8_gui_mask.nii.gz'\n",
    "\n",
    "# dilatemask result from nipype\n",
    "file_fsl_nipype = '../file4comparison/step_8_nipype_bold_dtype_mcf_bet_thresh_dil.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/envs/naturalistic/lib/python3.7/site-packages/nilearn/image/resampling.py:273: UserWarning: Resampling binary images with continuous or linear interpolation. This might lead to unexpected results. You might consider using nearest interpolation instead.\n",
      "  warnings.warn(\"Resampling binary images with continuous or \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238955,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/envs/naturalistic/lib/python3.7/site-packages/nilearn/image/resampling.py:273: UserWarning: Resampling binary images with continuous or linear interpolation. This might lead to unexpected results. You might consider using nearest interpolation instead.\n",
      "  warnings.warn(\"Resampling binary images with continuous or \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238955,)\n"
     ]
    }
   ],
   "source": [
    "brain_fsl_gui = Brain_Data(file_fsl_gui).data\n",
    "print(brain_fsl_gui.shape)\n",
    "brain_fsl_nipype = Brain_Data(file_fsl_nipype).data\n",
    "print(brain_fsl_nipype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 238955 voxels are different\n"
     ]
    }
   ],
   "source": [
    "diff = brain_fsl_gui - brain_fsl_nipype\n",
    "num_of_non_zeros = np.count_nonzero(diff)\n",
    "print(f\"{num_of_non_zeros} out of {diff.size} voxels are different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 9: Compare the result of maskfunc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask the motion corrected functional runs with the dilated mask\n",
    "\n",
    "In our **nipype** notebook, this corresponds to the node `maskfunc2`,\n",
    "\n",
    "\n",
    "In **fsl**, you can use the command from your fsl logfile, for example:\n",
    "\n",
    "```\n",
    "/opt/fsl-6.0.4/bin/fslmaths prefiltered_func_data_mcf -mas mask prefiltered_func_data_thresh\n",
    "```\n",
    "\n",
    "Output file: `prefiltered_func_data_thresh.nii.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maskfunc2 result from fsl gui\n",
    "file_fsl_gui = '../file4comparison/step_9_gui_prefiltered_func_data_thresh.nii.gz'\n",
    "\n",
    "# maskfunc2 result from nipype\n",
    "file_fsl_nipype = '../file4comparison/step_9_nipype_bold_dtype_mcf_thresh.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 238955)\n",
      "(146, 238955)\n"
     ]
    }
   ],
   "source": [
    "brain_fsl_gui = Brain_Data(file_fsl_gui).data\n",
    "print(brain_fsl_gui.shape)\n",
    "brain_fsl_nipype = Brain_Data(file_fsl_nipype).data\n",
    "print(brain_fsl_nipype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 34887430 voxels are different\n"
     ]
    }
   ],
   "source": [
    "diff = brain_fsl_gui - brain_fsl_nipype\n",
    "num_of_non_zeros = np.count_nonzero(diff)\n",
    "print(f\"{num_of_non_zeros} out of {diff.size} voxels are different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 10: Compare the result of SUSAN Noise Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.1: Determine the mean image from each TR\n",
    "\n",
    "10.2: Determine the median value of the TRs using the mask\n",
    "\n",
    "10.3: Merge the median values with the mean functional images into a coupled list. The output of this merge node will go into susan as usans\n",
    "\n",
    "10.4: Smooth each run using SUSAN with the brightness threshold set to 75% of the median value for each run and a mask constituting the mean functional\n",
    "\n",
    "\n",
    "Mask the motion corrected functional runs with the dilated mask\n",
    "\n",
    "In our **nipype** notebook, this corresponds to the node `meanfunc2`, `medianval`, `mergenode`, & `smooth`\n",
    "\n",
    "\n",
    "In **fsl**, you can use the command from your fsl logfile, for example:\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslmaths prefiltered_func_data_thresh -Tmean mean_func\n",
    "\n",
    "/usr/local/fsl/bin/fslstats prefiltered_func_data_mcf -k mask -p 50\n",
    "728.800232 (this number is for subject-11 run-01)\n",
    "\n",
    "/usr/local/fsl/bin/susan prefiltered_func_data_thresh 546.600174 2.12314225053 3 1 1 mean_func 546.600174 prefiltered_func_data_smooth\n",
    "\n",
    "```\n",
    "In **fsl GUI**, it corresponds to \n",
    "\n",
    "![image](https://user-images.githubusercontent.com/20402800/125663421-302ddfb6-9438-4e8d-aa7a-48200416722f.png)\n",
    "\n",
    "\n",
    "Output file: `prefiltered_func_data_smooth.nii.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>\n",
    "    Later, FSL applied other transformations on this smoothed file without renaming, so if executing this step afterwards, results might be different. \n",
    "    Thus, we did not provide files for this step.\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 11: Compare the result of maskfunc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask the smoothed data with the dilated mask\n",
    "\n",
    "In our **nipype** notebook, this corresponds to the node `maskfunc3`\n",
    "\n",
    "\n",
    "In **fsl**, you can use the command from your fsl logfile, for example:\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslmaths prefiltered_func_data_smooth -mas mask prefiltered_func_data_smooth\n",
    "\n",
    "```\n",
    "\n",
    "This step performs on `prefiltered_func_data_smooth.nii.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Version A: FWHM = 4.9996179300001655 in Nipype\n",
    "\n",
    "In the FSL GUI where SUSAN noise reduction is specified, a brightness threshold (bt) is needed and estimated from a FWHM smoothing kernel. Surprisingly, even a slight difference in bt can lead to very different results in the final stage of the GLM analysis. We used FWHM as 5 mm in FSL and obtained a bt of 2.12314225053. Yet, Nipype uses a different algorithm (bt = float(fwhm) / np.sqrt(8 * np.log(2))) to calculate bt from FSL. Therefore, to acquire the same bt, FWHM should be set as **4.9996179300001655** in Nipype rather than 5.\n",
    "\n",
    "Output file: \n",
    "- `prefiltered_func_data_smooth.nii.gz` in FSL\n",
    "- `...smooth_maths.nii.gz` in Nipype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholding result from fsl gui\n",
    "file_fsl_gui = '../file4comparison/step_11_gui_prefiltered_func_data_smooth.nii.gz'\n",
    "\n",
    "# thresholding result from nipype\n",
    "file_fsl_nipype = '../file4comparison/step_11_nipype_A_bold_dtype_mcf_thresh_smooth_maths.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 238955)\n",
      "(146, 238955)\n"
     ]
    }
   ],
   "source": [
    "brain_fsl_gui = Brain_Data(file_fsl_gui).data\n",
    "print(brain_fsl_gui.shape)\n",
    "brain_fsl_nipype = Brain_Data(file_fsl_nipype).data\n",
    "print(brain_fsl_nipype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 34887430 voxels are different\n"
     ]
    }
   ],
   "source": [
    "diff = brain_fsl_gui - brain_fsl_nipype\n",
    "num_of_non_zeros = np.count_nonzero(diff)\n",
    "print(f\"{num_of_non_zeros} out of {diff.size} voxels are different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Version B: FWHM = 5 in Nipype\n",
    "\n",
    "Here we set FWHM = 5 in both Nipype and FSL to demonstrate how different the results will be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth result from fsl gui\n",
    "file_fsl_gui = '../file4comparison/step_11_gui_prefiltered_func_data_smooth.nii.gz'\n",
    "\n",
    "# smooth result from nipype\n",
    "file_fsl_nipype = '../file4comparison/step_11_nipype_B_bold_dtype_mcf_thresh_smooth_maths.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 238955)\n",
      "(146, 238955)\n"
     ]
    }
   ],
   "source": [
    "brain_fsl_gui = Brain_Data(file_fsl_gui).data\n",
    "print(brain_fsl_gui.shape)\n",
    "brain_fsl_nipype = Brain_Data(file_fsl_nipype).data\n",
    "print(brain_fsl_nipype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27981621 out of 34887430 voxels are different\n"
     ]
    }
   ],
   "source": [
    "diff = brain_fsl_gui - brain_fsl_nipype\n",
    "num_of_non_zeros = np.count_nonzero(diff)\n",
    "print(f\"{num_of_non_zeros} out of {diff.size} voxels are different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 12: Compare the result of intnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale each volume of the run so that the median value of the run is set to 10000\n",
    "\n",
    "\n",
    "In our **nipype** notebook, this corresponds to the node `intnorm`\n",
    "\n",
    "\n",
    "In **fsl**, you can use the command from your fsl logfile, for example:\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslmaths prefiltered_func_data_smooth -mul 13.7211811425 prefiltered_func_data_intnorm \n",
    "(this number is for subject-11 run-01)\n",
    "\n",
    "```\n",
    "\n",
    "Output file: `prefiltered_func_data_intnorm.nii.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intnorm result from fsl gui\n",
    "file_fsl_gui = '../file4comparison/step_12_gui_prefiltered_func_data_intnorm.nii.gz'\n",
    "\n",
    "# intnorm result from nipype\n",
    "file_fsl_nipype = '../file4comparison/step_12_nipype_bold_dtype_mcf_thresh_smooth_maths_intnorm.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 238955)\n",
      "(146, 238955)\n"
     ]
    }
   ],
   "source": [
    "brain_fsl_gui = Brain_Data(file_fsl_gui).data\n",
    "print(brain_fsl_gui.shape)\n",
    "brain_fsl_nipype = Brain_Data(file_fsl_nipype).data\n",
    "print(brain_fsl_nipype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 34887430 voxels are different\n"
     ]
    }
   ],
   "source": [
    "diff = brain_fsl_gui - brain_fsl_nipype\n",
    "num_of_non_zeros = np.count_nonzero(diff)\n",
    "print(f\"{num_of_non_zeros} out of {diff.size} voxels are different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 13: Compare the result of Temporal Filtering (last step of preproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.1: Generate a mean functional image from the scaled data\n",
    "\n",
    "13.2: Perform temporal highpass filtering on the data\n",
    "\n",
    "13.3: Rename `prefiltered_func_data_tempfilt.nii.gz` as `filtered_func_data.nii.gz`\n",
    "\n",
    "\n",
    "In our **nipype** notebook, this corresponds to the node `intnorm`\n",
    "\n",
    "\n",
    "In **fsl**, you can use the command from your fsl logfile, for example:\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslmaths prefiltered_func_data_intnorm -Tmean tempMean\n",
    "/usr/local/fsl/bin/fslmaths prefiltered_func_data_intnorm -bptf 25.0 -1 -add tempMean prefiltered_func_data_tempfilt\n",
    "/usr/local/fsl/bin/fslmaths prefiltered_func_data_tempfilt filtered_func_data\n",
    "\n",
    "```\n",
    "\n",
    "In **fsl GUI**, it corresponds to\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/20402800/125667188-68e8000e-307b-42e9-804a-c4b6dffa36a5.png)\n",
    "\n",
    "Output file: `filtered_func_data.nii.gz` (**This is our final preoprocessed bold data**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.1: Generate a mean functional image from the scaled data\n",
    "\n",
    "Output file: `tempMean.nii.gz`\n",
    "\n",
    "<mark>\n",
    "    We did not provide files for this step since this file will be removed at the end of the preprocessing.\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.2 & 13.3: Perform temporal highpass filtering on the data & Rename\n",
    "\n",
    "\n",
    "Output file: `prefiltered_func_data_tempfilt.nii.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholding result from fsl gui\n",
    "file_fsl_gui = '../file4comparison/step_13_gui_filtered_func_data.nii.gz'\n",
    "\n",
    "# thresholding result from nipype\n",
    "file_fsl_nipype = '../file4comparison/step_13_nipype_bold_dtype_mcf_thresh_smooth_maths_intnorm_tempfilt.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 238955)\n",
      "(146, 238955)\n"
     ]
    }
   ],
   "source": [
    "brain_fsl_gui = Brain_Data(file_fsl_gui).data\n",
    "print(brain_fsl_gui.shape)\n",
    "brain_fsl_nipype = Brain_Data(file_fsl_nipype).data\n",
    "print(brain_fsl_nipype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 34887430 voxels are different\n"
     ]
    }
   ],
   "source": [
    "diff = brain_fsl_gui - brain_fsl_nipype\n",
    "num_of_non_zeros = np.count_nonzero(diff)\n",
    "print(f\"{num_of_non_zeros} out of {diff.size} voxels are different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 14: Compare the result of meanfunc4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a mean functional image from the functional run (**This will be used in glm**)\n",
    "\n",
    "\n",
    "In our **nipype** notebook, this corresponds to the node `meanfunc4`\n",
    "\n",
    "\n",
    "In **fsl**, you can use the command from your fsl logfile, for example:\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslmaths filtered_func_data -Tmean mean_func\n",
    "\n",
    "```\n",
    "\n",
    "Output file: `mean_func.nii.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meanfunc4 result from fsl gui\n",
    "file_fsl_gui = '../file4comparison/step_14_gui_mean_func.nii.gz'\n",
    "\n",
    "# meanfunc4 result from nipype\n",
    "file_fsl_nipype = '../file4comparison/step_14_nipype_bold_dtype_mcf_thresh_smooth_maths_intnorm_tempfilt_mean.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238955,)\n",
      "(238955,)\n"
     ]
    }
   ],
   "source": [
    "brain_fsl_gui = Brain_Data(file_fsl_gui).data\n",
    "print(brain_fsl_gui.shape)\n",
    "brain_fsl_nipype = Brain_Data(file_fsl_nipype).data\n",
    "print(brain_fsl_nipype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 238955 voxels are different\n"
     ]
    }
   ],
   "source": [
    "diff = brain_fsl_gui - brain_fsl_nipype\n",
    "num_of_non_zeros = np.count_nonzero(diff)\n",
    "print(f\"{num_of_non_zeros} out of {diff.size} voxels are different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First-level GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 15: Compare the result of the First-level GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vesion A\n",
    "\n",
    "In this version, all parameters are set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cope result from fsl gui\n",
    "file_fsl_gui = '../file4comparison/step_15_gui_cope1.nii.gz'\n",
    "\n",
    "# cope result from nipype\n",
    "file_fsl_nipype = '../file4comparison/step_15_nipype_A_cope1.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238955,)\n",
      "(238955,)\n"
     ]
    }
   ],
   "source": [
    "brain_fsl_gui = Brain_Data(file_fsl_gui).data\n",
    "print(brain_fsl_gui.shape)\n",
    "brain_fsl_nipype = Brain_Data(file_fsl_nipype).data\n",
    "print(brain_fsl_nipype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 238955 voxels are different\n"
     ]
    }
   ],
   "source": [
    "diff = brain_fsl_gui - brain_fsl_nipype\n",
    "num_of_non_zeros = np.count_nonzero(diff)\n",
    "print(f\"{num_of_non_zeros} out of {diff.size} voxels are different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version B\n",
    "\n",
    "In this version, we compare the first-level result when FWHM = 5 in both Nipype and FSL (see Step 11 for more information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cope result from fsl gui\n",
    "file_fsl_gui = '../file4comparison/step_15_gui_cope1.nii.gz'\n",
    "\n",
    "# cope result from nipype\n",
    "file_fsl_nipype = '../file4comparison/step_15_nipype_B_cope1.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238955,)\n",
      "(238955,)\n"
     ]
    }
   ],
   "source": [
    "brain_fsl_gui = Brain_Data(file_fsl_gui).data\n",
    "print(brain_fsl_gui.shape)\n",
    "brain_fsl_nipype = Brain_Data(file_fsl_nipype).data\n",
    "print(brain_fsl_nipype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223069 out of 238955 voxels are different\n"
     ]
    }
   ],
   "source": [
    "diff = brain_fsl_gui - brain_fsl_nipype\n",
    "num_of_non_zeros = np.count_nonzero(diff)\n",
    "print(f\"{num_of_non_zeros} out of {diff.size} voxels are different\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Difference')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(diff, linestyle='-', color='orange')\n",
    "plt.xlabel(\"Voxel\", fontsize=16)\n",
    "plt.ylabel(\"Difference\", fontsize=16)\n",
    "# plt.savefig(\"../figures/comparison_FWHM_5.jpeg\",dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second-level GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part, we compare results of `sub-02` from FSL GUI and Nipype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 16: Compare the result of Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the second-level GLM, we need to register outputs from the first level into a standardized space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized cope result from fsl gui\n",
    "file_fsl_gui = '../file4comparison/step_16_gui_cope1.nii.gz'\n",
    "\n",
    "# standardized cope result from nipype\n",
    "file_fsl_nipype = '../file4comparison/step_16_nipype_cope1_flirt.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238955,)\n",
      "(238955,)\n"
     ]
    }
   ],
   "source": [
    "brain_fsl_gui = Brain_Data(file_fsl_gui).data\n",
    "print(brain_fsl_gui.shape)\n",
    "brain_fsl_nipype = Brain_Data(file_fsl_nipype).data\n",
    "print(brain_fsl_nipype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 238955 voxels are different\n"
     ]
    }
   ],
   "source": [
    "diff = brain_fsl_gui - brain_fsl_nipype\n",
    "num_of_non_zeros = np.count_nonzero(diff)\n",
    "print(f\"{num_of_non_zeros} out of {diff.size} voxels are different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16.2 compare example_func2highres & highres2standard\n",
    "\n",
    "`example_func2highres.mat` & `highres2example_func.mat`\n",
    "\n",
    "4X4 matrices, eyeball they are the same.\n",
    "\n",
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/flirt -in example_func -ref highres -out example_func2highres -omat example_func2highres.mat -cost corratio -dof 12 -searchrx -180 180 -searchry -180 180 -searchrz -180 180 -interp trilinear \n",
    "\n",
    "/usr/local/fsl/bin/convert_xfm -inverse -omat highres2example_func.mat example_func2highres.mat\n",
    "```\n",
    "\n",
    "`standard2highres.mat` & `highres2standard.mat`\n",
    "\n",
    "4X4 matrices, eyeball they are the same.\n",
    "\n",
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/flirt -in highres -ref standard -out highres2standard -omat highres2standard.mat -cost corratio -dof 12 -searchrx -180 180 -searchry -180 180 -searchrz -180 180 -interp trilinear \n",
    "\n",
    "/usr/local/fsl/bin/convert_xfm -inverse -omat standard2highres.mat highres2standard.mat\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 17: Compare the result of the Second-level GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res4d result from fsl gui\n",
    "file_fsl_gui = '../file4comparison/step_17_gui_cope1.nii.gz'\n",
    "\n",
    "# meanfunc4 result from nipype\n",
    "file_fsl_nipype = '../file4comparison/step_17_nipype_cope1.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238955,)\n",
      "(238955,)\n"
     ]
    }
   ],
   "source": [
    "brain_fsl_gui = Brain_Data(file_fsl_gui).data\n",
    "print(brain_fsl_gui.shape)\n",
    "brain_fsl_nipype = Brain_Data(file_fsl_nipype).data\n",
    "print(brain_fsl_nipype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 238955 voxels are different\n"
     ]
    }
   ],
   "source": [
    "diff = brain_fsl_gui - brain_fsl_nipype\n",
    "num_of_non_zeros = np.count_nonzero(diff)\n",
    "print(f\"{num_of_non_zeros} out of {diff.size} voxels are different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Third-level GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the output from the third contrast as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 18: Compare the result of the Third-level GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238955,)\n",
      "(238955,)\n"
     ]
    }
   ],
   "source": [
    "file_fsl_gui = '../file4comparison/step_18_gui_cope1.nii.gz'\n",
    "brain_fsl_gui = Brain_Data(file_fsl_gui).data\n",
    "print(brain_fsl_gui.shape)\n",
    "file_fsl_nipype = '../file4comparison/step_18_nipype_cope1.nii.gz'\n",
    "brain_fsl_nipype = Brain_Data(file_fsl_nipype).data\n",
    "print(brain_fsl_nipype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 238955 voxels are different\n"
     ]
    }
   ],
   "source": [
    "diff = brain_fsl_gui - brain_fsl_nipype\n",
    "num_of_non_zeros = np.count_nonzero(diff)\n",
    "print(f\"{num_of_non_zeros} out of {diff.size} voxels are different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 19: Compare the thresholded results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238955,)\n",
      "(238955,)\n"
     ]
    }
   ],
   "source": [
    "file_fsl_gui = '../file4comparison/step_19_gui_thresh_zstat1.nii.gz'\n",
    "brain_fsl_gui = Brain_Data(file_fsl_gui).data\n",
    "print(brain_fsl_gui.shape)\n",
    "file_fsl_nipype = '../file4comparison/step_19_nipype_zstat1_maths_threshold.nii.gz'\n",
    "brain_fsl_nipype = Brain_Data(file_fsl_nipype).data\n",
    "print(brain_fsl_nipype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 238955 voxels are different\n"
     ]
    }
   ],
   "source": [
    "diff = brain_fsl_gui - brain_fsl_nipype\n",
    "num_of_non_zeros = np.count_nonzero(diff)\n",
    "print(f\"{num_of_non_zeros} out of {diff.size} voxels are different\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
