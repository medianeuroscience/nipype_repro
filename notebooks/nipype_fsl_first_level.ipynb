{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First-level GLM using Nipype FSL\n",
    "\n",
    "In this notebook, we recreate the first-level GLM and the first level GLM of FSL GUI using nipype code. For each nipype node, we list the corresponding fsl command from the log file. The dataset we use is a Flanker task, which can be downloaded [here](https://openneuro.org/datasets/ds000102/versions/00001).\n",
    "\n",
    "We also borrow some helps from this [document](https://nipype.readthedocs.io/en/latest/users/examples/fmri_fsl.html). \n",
    "\n",
    "**12/05/2021**\n",
    "We modified two parts:\n",
    "1. simplified the registration part - now it is the same as FSL command\n",
    "2. save all first-level outputs into single/separate folder for further analysis use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "Import all the relevant libraries needed for the preprocessing stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from builtins import str\n",
    "from builtins import range\n",
    "\n",
    "import os, stat  # system functions\n",
    "import getpass\n",
    "from glob import glob\n",
    "\n",
    "from nipype import Function\n",
    "import nipype.interfaces.io as nio  # Data i/o\n",
    "import nipype.interfaces.fsl as fsl  # fsl\n",
    "import nipype.interfaces.utility as util  # utility\n",
    "import nipype.pipeline.engine as pe  # pypeline engine\n",
    "import nipype.algorithms.modelgen as model  # model generation\n",
    "import nipype.algorithms.rapidart as ra  # artifact detection\n",
    "\n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current user\n",
    "user = getpass.getuser()\n",
    "print('Running code as: ', user)\n",
    "\n",
    "# Set the BIDS path\n",
    "data_dir = '/home/{}/data/'.format(user)\n",
    "# Set path where nipype will store stepwise results (e.g., masks)\n",
    "exp_dir = '/home/{}/out/fsl/hw2/'.format(user)\n",
    "\n",
    "try:\n",
    "    os.mkdir(exp_dir)\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "    \n",
    "    \n",
    "# Grant root write access to our output files \n",
    "os.chmod(exp_dir, os.stat(exp_dir).st_mode | ((stat.S_IRWXU | stat.S_IRWXO)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = pe.Workflow(name='level1', base_dir=exp_dir)\n",
    "wf.config[\"execution\"][\"crashfile_format\"] = \"txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two nodes (`infosource` & `dg`) together define all inputs required for the preprocessing workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get subject_id list\n",
    "subj_list = [x.split('-')[1] for x in glob(data_dir+\"sub*\")]\n",
    "subj_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "infosource = pe.Node(util.IdentityInterface(fields=[\"subject_id\"]),\n",
    "                  name=\"infosource\")\n",
    "infosource.iterables = [(\"subject_id\", subj_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = pe.Node(\n",
    "    interface=nio.DataGrabber(\n",
    "        infields=[\"subject_id\",\"run_id\"], outfields=[\"struct\", \"func\", \"events\"]\n",
    "    ),\n",
    "    name=\"dg\"\n",
    ")\n",
    "\n",
    "# Specify task names and return a sorted filelist to ensure we match files to correct runs/tasks\n",
    "dg.inputs.run_id = [1,2]\n",
    "dg.inputs.sort_filelist = True\n",
    "dg.inputs.template = \"*\"\n",
    "dg.inputs.base_directory = data_dir\n",
    "\n",
    "\n",
    "# Define arguments fill the wildcards in the below paths \n",
    "dg.inputs.template_args = dict(\n",
    "    struct=[[\"subject_id\",\"subject_id\"]],\n",
    "    func=[[\"subject_id\",\"subject_id\",\"run_id\"]],\n",
    "    events=[[\"subject_id\",\"subject_id\",\"run_id\"]]\n",
    ")\n",
    "\n",
    "# bold – Preprocessed BOLD run spatially normalized to standard space\n",
    "# mask – Brain mask corresponding to preprocessed BOLD run, in standard space\n",
    "# events – Original events ﬁle that describes when the subject was exposed to the experimental manipulation\n",
    "# regressors – Confound signals, a ﬁle corresponding to each BOLD run \n",
    "\n",
    "dg.inputs.field_template = dict(\n",
    "    struct = \"sub-%s/anat/sub-%s_T1w.nii.gz\",\n",
    "    func=\"sub-%s/func/sub-%s_task-flanker_run-%d_bold.nii.gz\",\n",
    "    events=\"sub-%s/func/sub-%s_task-flanker_run-%d_events.tsv\", \n",
    ")\n",
    "\n",
    "\n",
    "wf.connect([\n",
    "        (infosource, dg, [(\"subject_id\", \"subject_id\")])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Convert functional images to float representation. Since there can be more than one functional run we use a MapNode to convert each run.\n",
    "\n",
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslmaths ../sub-11/func/sub-11_task-flanker_run-1_bold prefiltered_func_data -odt float\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2float = pe.MapNode(\n",
    "    interface=fsl.ImageMaths(out_data_type='float', op_string='', suffix='_dtype'),\n",
    "    name='img2float',\n",
    "    iterfield=['in_file'])\n",
    "wf.connect(dg, 'func', img2float, 'in_file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the middle volume of the first run as the reference\n",
    "\n",
    "(Head movement, motion-correction)\n",
    "\n",
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslroi prefiltered_func_data example_func 73 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract one roi\n",
    "extract_ref = pe.MapNode(interface=fsl.ExtractROI(t_size=1), \n",
    "                         name='extractref',\n",
    "                         iterfield=['in_file'])\n",
    "\n",
    "# Define a function to pick the first file from a list of files\n",
    "\n",
    "\n",
    "wf.connect(img2float, 'out_file', extract_ref, 'in_file')\n",
    "\n",
    "# Define a function to return the 1 based index of the middle volume\n",
    "\n",
    "def getmiddlevolume(func):\n",
    "    from nibabel import load\n",
    "    funcfile = func\n",
    "    if isinstance(func, list):\n",
    "        funcfile = func[0]\n",
    "    _, _, _, timepoints = load(funcfile).shape\n",
    "    return int(timepoints/2) \n",
    "\n",
    "\n",
    "wf.connect(img2float, ('out_file', getmiddlevolume), extract_ref, 't_min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realign the functional runs to the middle volume of each run\n",
    "\n",
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/mcflirt -in prefiltered_func_data -out prefiltered_func_data_mcf -mats -plots -reffile example_func -rmsrel -rmsabs -spline_final\n",
    "```\n",
    "\n",
    "```\n",
    "save_mats (a boolean) – Save transformation matrices. Maps to a command-line argument: -mats.\n",
    "save_plots (a boolean) – Save transformation parameters. Maps to a command-line argument: -plots.\n",
    "save_rms (a boolean) – Save rms displacement parameters. Maps to a command-line argument: -rmsabs -rmsrel.\n",
    "Interpolation (‘spline’ or ‘nn’ or ‘sinc’) – Interpolation method for transformation. Maps to a command-line argument: -%s_final.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_correct = pe.MapNode(\n",
    "    interface=fsl.MCFLIRT(save_mats=True, save_plots=True, save_rms=True, interpolation='spline'),\n",
    "    name='realign',\n",
    "    iterfield=['in_file','ref_file'])\n",
    "wf.connect(img2float, 'out_file', motion_correct, 'in_file')\n",
    "wf.connect(extract_ref, 'roi_file', motion_correct, 'ref_file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the estimated motion parameters\n",
    "\n",
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fsl_tsplot -i prefiltered_func_data_mcf.par -t 'MCFLIRT estimated rotations (radians)' -u 1 --start=1 --finish=3 -a x,y,z -w 640 -h 144 -o rot.png \n",
    "\n",
    "/usr/local/fsl/bin/fsl_tsplot -i prefiltered_func_data_mcf.par -t 'MCFLIRT estimated translations (mm)' -u 1 --start=4 --finish=6 -a x,y,z -w 640 -h 144 -o trans.png \n",
    "\n",
    "/usr/local/fsl/bin/fsl_tsplot -i prefiltered_func_data_mcf_abs.rms,prefiltered_func_data_mcf_rel.rms -t 'MCFLIRT estimated mean displacement (mm)' -u 1 -w 640 -h 144 -a absolute,relative -o disp.png\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_motion = pe.MapNode(\n",
    "    interface=fsl.PlotMotionParams(in_source='fsl'),\n",
    "    name='plot_motion',\n",
    "    iterfield=['in_file'])\n",
    "plot_motion.iterables = ('plot_type', ['rotations', 'translations','displacement'])\n",
    "wf.connect(motion_correct, 'par_file', plot_motion, 'in_file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionally Masking\n",
    "\n",
    "```\n",
    "Passing the reference volume to the FSL command-line tool bet to generate a binary brain mask and afterward multiplying the processed functional time series by the brain mask using the fslmaths command to produce a skull-stripped time series.\n",
    "```\n",
    "\n",
    "See [Ciric et al.(2018)](https://www.nature.com/articles/s41596-018-0065-y#Sec24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the mean volume of each functional run\n",
    "\n",
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslmaths prefiltered_func_data_mcf -Tmean mean_func\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanfunc = pe.MapNode(\n",
    "    interface=fsl.ImageMaths(op_string='-Tmean', suffix='_mean'),\n",
    "    name='meanfunc',\n",
    "    iterfield=['in_file'])\n",
    "wf.connect(motion_correct, 'out_file', meanfunc, 'in_file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strip the skull from the mean functional to generate a mask\n",
    "\n",
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/bet2 mean_func mask -f 0.3 -n -m; /usr/local/fsl/bin/immv mask_mask mask\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanfuncmask = pe.MapNode(\n",
    "    interface=fsl.BET(mask=True, no_output=True, frac=0.3),\n",
    "    name='meanfuncmask',\n",
    "    iterfield=['in_file'])\n",
    "wf.connect(meanfunc, 'out_file', meanfuncmask, 'in_file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask the functional data with the extracted mask\n",
    "\n",
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslmaths prefiltered_func_data_mcf -mas mask prefiltered_func_data_bet\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskfunc = pe.MapNode(\n",
    "    interface=fsl.ImageMaths(suffix='_bet', op_string='-mas'),\n",
    "    name='maskfunc',\n",
    "    iterfield=['in_file','in_file2'])\n",
    "wf.connect(motion_correct, 'out_file', maskfunc, 'in_file')\n",
    "wf.connect(meanfuncmask, 'mask_file', maskfunc, 'in_file2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grand Mean Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the 2nd and 98th percentile intensities \n",
    "\n",
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslstats prefiltered_func_data_bet -p 2 -p 98\n",
    "0.000000 873.492249 (these numbers are for subject-11 run-01)\n",
    "```\n",
    "\n",
    "More info [here](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Fslutils#fslstats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "getthresh = pe.MapNode(\n",
    "    interface=fsl.ImageStats(op_string='-p 2 -p 98'),\n",
    "    name='getthreshold',\n",
    "    iterfield=['in_file'])\n",
    "wf.connect(maskfunc, 'out_file', getthresh, 'in_file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold the first TR of the functional data at 10% of the 98th percentile\n",
    "\n",
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslmaths prefiltered_func_data_bet -thr 87.3492249 -Tmin -bin mask -odt char\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = pe.MapNode(\n",
    "    interface=fsl.ImageMaths(out_data_type='char', suffix='_thresh'),\n",
    "    name='threshold',\n",
    "    iterfield=['in_file','op_string'])\n",
    "wf.connect(maskfunc, 'out_file', threshold, 'in_file')\n",
    "\n",
    "# Define a function to get 10% of the intensity\n",
    "def getthreshop(thresh):\n",
    "    \n",
    "    return ['-thr %.10f -Tmin -bin' % (0.1 * th[1]) for th in thresh]\n",
    "\n",
    "wf.connect(getthresh, ('out_stat', getthreshop), threshold, 'op_string')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the median value of the TRs using the mask\n",
    "\n",
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslstats prefiltered_func_data_mcf -k mask -p 50\n",
    "728.800232 (this number is for subject-11 run-01)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "medianval = pe.MapNode(\n",
    "    interface=fsl.ImageStats(op_string='-k %s -p 50'),\n",
    "    name='medianval',\n",
    "    iterfield=['in_file','mask_file'])\n",
    "wf.connect(motion_correct, 'out_file', medianval, 'in_file')\n",
    "wf.connect(threshold, 'out_file', medianval, 'mask_file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dilate the mask\n",
    "\n",
    "The brain mask is \"dilated\" slightly before being used. Because it is normally important that masking be liberal (ie that there be little risk of cutting out valid brain voxels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslmaths mask -dilF mask\n",
    "```\n",
    "\n",
    "The output of `dilatemask` (i.e., `/srv/scratch/yc/fsl/hw2/level1/_subject_id_26/dilatemask/mapflow/_dilatemask0/sub-26_task-flanker_run-1_bold_dtype_mcf_bet_thresh_dil.nii.gz`) is equivalent to `mask.nii.gz` from FSL GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilatemask = pe.MapNode(\n",
    "    interface=fsl.ImageMaths(suffix='_dil', op_string='-dilF'),\n",
    "    name='dilatemask',\n",
    "    iterfield=['in_file'])\n",
    "wf.connect(threshold, 'out_file', dilatemask, 'in_file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask the motion corrected functional runs with the dilated mask\n",
    "\n",
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslmaths prefiltered_func_data_mcf -mas mask prefiltered_func_data_thresh\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskfunc2 = pe.MapNode(\n",
    "    interface=fsl.ImageMaths(suffix='_thresh', op_string='-mas'),\n",
    "    iterfield=['in_file','in_file2'],\n",
    "    name='maskfunc2')\n",
    "wf.connect(motion_correct, 'out_file', maskfunc2, 'in_file')\n",
    "wf.connect(dilatemask, 'out_file', maskfunc2, 'in_file2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUSAN Noise Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the mean image from each TR\n",
    "\n",
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslmaths prefiltered_func_data_thresh -Tmean mean_func\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanfunc2 = pe.MapNode(\n",
    "    interface=fsl.ImageMaths(op_string='-Tmean', suffix='_mean'),\n",
    "    name='meanfunc2',\n",
    "    iterfield=['in_file'])\n",
    "wf.connect(maskfunc2, 'out_file', meanfunc2, 'in_file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the median values with the mean functional images into a coupled list\n",
    "\n",
    "The output of this `merge` node will go into `susan` as `usans`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why here use node not mapnode?\n",
    "mergenode = pe.Node(interface=util.Merge(2, axis='hstack'), \n",
    "                       name='merge')\n",
    "wf.connect(meanfunc2, 'out_file', mergenode, 'in1')\n",
    "wf.connect(medianval, 'out_stat', mergenode, 'in2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smooth each run using SUSAN with the brightness threshold set to 75% of the median value for each run and a mask constituting the mean functional\n",
    "\n",
    "```\n",
    "Usage: susan <input> <bt> <dt> <dim> <use_median> <n_usans> [<usan1> <bt1> [<usan2> <bt2>]] <output>\n",
    "<bt> is brightness threshold and should be greater than noise level and less than contrast of edges to be preserved.\n",
    "<dt> is spatial size (sigma, i.e., half-width) of smoothing, in mm.\n",
    "<dim> is dimensionality (2 or 3), depending on whether smoothing is to be within-plane (2) or fully 3D (3).\n",
    "<use_median> determines whether to use a local median filter in the cases where single-point noise is detected (0 or 1).\n",
    "<n_usans> determines whether the smoothing area (USAN) is to be found from secondary images (0, 1 or 2).\n",
    "A negative value for any brightness threshold will auto-set the threshold at 10% of the robust range\n",
    "```\n",
    "\n",
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/susan prefiltered_func_data_thresh 546.600174 2.12314225053 3 1 1 mean_func 546.600174 prefiltered_func_data_smooth\n",
    "```\n",
    "\n",
    "**Note:**\n",
    "\n",
    "for `<bt>`, Nipype uses a different algorithm to calculate it -> `float(fwhm) / np.sqrt(8 * np.log(2))`. Therefore, to get `2.12314225053`, fwhm should be `4.9996179300001655` instead of `5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwhm_thr = 4.9996179300001655\n",
    "\n",
    "smooth = pe.MapNode(\n",
    "    interface=fsl.SUSAN(fwhm = fwhm_thr),\n",
    "    name='smooth',\n",
    "    iterfield=['in_file', 'brightness_threshold', 'usans'])\n",
    "\n",
    "# Define a function to get the brightness threshold for SUSAN\n",
    "def getbtthresh(medianvals):\n",
    "    return [0.75 * val for val in medianvals]\n",
    "\n",
    "\n",
    "def getusans(x):\n",
    "    return [[tuple([val[0], 0.75 * val[1]])] for val in x]\n",
    "\n",
    "\n",
    "wf.connect(maskfunc2, 'out_file', smooth, 'in_file')\n",
    "wf.connect(medianval, ('out_stat', getbtthresh), smooth,\n",
    "                'brightness_threshold')\n",
    "wf.connect(mergenode, ('out', getusans), smooth, 'usans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask the smoothed data with the dilated mask\n",
    "\n",
    "\n",
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslmaths prefiltered_func_data_smooth -mas mask prefiltered_func_data_smooth\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskfunc3 = pe.MapNode(\n",
    "    interface=fsl.ImageMaths(op_string='-mas'),\n",
    "    name='maskfunc3',\n",
    "    iterfield=['in_file','in_file2'])\n",
    "wf.connect(smooth, 'smoothed_file', maskfunc3, 'in_file')\n",
    "wf.connect(dilatemask, 'out_file', maskfunc3, 'in_file2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale each volume of the TR so that the median value of the TR is set to 10000\n",
    "\n",
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslmaths prefiltered_func_data_smooth -mul 13.7211811425 prefiltered_func_data_intnorm \n",
    "(this number is for subject-11 run-01)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "intnorm = pe.MapNode(\n",
    "    interface=fsl.ImageMaths(suffix='_intnorm'),\n",
    "    iterfield=['in_file', 'op_string'],\n",
    "    name='intnorm')\n",
    "wf.connect(maskfunc3, 'out_file', intnorm, 'in_file')\n",
    "\n",
    "# Define a function to get the scaling factor for intensity normalization\n",
    "def getinormscale(medianvals):\n",
    "    return ['-mul %.10f' % (10000. / val) for val in medianvals]\n",
    "\n",
    "\n",
    "wf.connect(medianval, ('out_stat', getinormscale), intnorm, 'op_string')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform temporal highpass filtering on the data\n",
    "\n",
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslmaths prefiltered_func_data_intnorm -Tmean tempMean\n",
    "/usr/local/fsl/bin/fslmaths prefiltered_func_data_intnorm -bptf 25.0 -1 -add tempMean prefiltered_func_data_tempfilt\n",
    "```\n",
    "\n",
    "The output of `highpass` (i.e., `sub-11_task-flanker_run-1_bold_dtype_mcf_mask_smooth_mask_intnorm_tempfilt.nii.gz`) is equivalent to `filtered_func_data.nii.gz` from FSL GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a mean functional image from the scaled data and this mean func will be used in performing temporal highpass filtering\n",
    "meanfunc3 = pe.MapNode(\n",
    "    interface=fsl.ImageMaths(op_string='-Tmean'),\n",
    "    iterfield=['in_file'],\n",
    "    name='meanfunc3')\n",
    "wf.connect(intnorm, 'out_file', meanfunc3, 'in_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform temporal highpass filtering on the data\n",
    "hpcutoff = 100\n",
    "TR = 2.  # ensure float\n",
    "\n",
    "highpass = pe.MapNode(\n",
    "    interface=fsl.ImageMaths(suffix='_tempfilt'),\n",
    "    name='highpass',\n",
    "    iterfield=['in_file','op_string'])\n",
    "\n",
    "# 25 = (hpcutoff / 2*TR) not (hpcutoff / TR)\n",
    "def gethpstring(tempMean):\n",
    "    return ['-bptf 25 -1 -add %s' % (tm) for tm in tempMean]\n",
    "\n",
    "wf.connect(intnorm, 'out_file', highpass, 'in_file')\n",
    "wf.connect(meanfunc3, ('out_file',gethpstring), highpass, 'op_string')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a mean functional image from the functional run\n",
    "\n",
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/fslmaths prefiltered_func_data_tempfilt filtered_func_data\n",
    "/usr/local/fsl/bin/fslmaths filtered_func_data -Tmean mean_func\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanfunc4 = pe.MapNode(\n",
    "    interface=fsl.ImageMaths(op_string='-Tmean', suffix='_mean'),\n",
    "    iterfield=['in_file'],\n",
    "    name='meanfunc4')\n",
    "wf.connect(highpass, 'out_file', meanfunc4, 'in_file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## First-Level GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjinfo(events):\n",
    "    from nipype.interfaces.base import Bunch\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    subject_info = []\n",
    "\n",
    "    ev = pd.read_csv(events, sep=\"\\t\")\n",
    "    ev = ev[ev['correctness']=='correct']\n",
    "    ev['new_type'] = ev['trial_type'].apply(lambda x: str(x).split('_')[0])\n",
    "\n",
    "    run_info = Bunch(onsets=[], \n",
    "                     durations=[])\n",
    "\n",
    "    run_info.set(conditions=[g[0] for g in ev.groupby(\"new_type\")])\n",
    "\n",
    "    for group in ev.groupby(\"new_type\"):\n",
    "        run_info.onsets.append(group[1].onset.tolist())\n",
    "        run_info.durations.append(group[1].duration.tolist())\n",
    "    subject_info.append(run_info)\n",
    "\n",
    "    return subject_info\n",
    "\n",
    "get_sub_info = pe.MapNode(\n",
    "    Function(\n",
    "        function=subjinfo, input_names=[\"events\"], output_names=\"subject_info\"\n",
    "    ),\n",
    "    name=\"get_sub_info\", iterfield=[\"events\"]\n",
    ")\n",
    "\n",
    "# Connect to workflow\n",
    "wf.connect(dg, 'events', get_sub_info, 'events')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_names = [\"congruent\", \"incongruent\"]\n",
    "\n",
    "# Activation Contrasts (similar to https://direct.mit.edu/jocn/article/23/10/3162/5327/Is-Morality-Unified-Evidence-that-Distinct-Neural)\n",
    "## From FEAT: \"The correct way to tell whether two conditions are significantly different is to run a differential contrast like [1 -1] between them\"\n",
    "cont01 = [\"congruent\", \"T\", condition_names,  [1, 0]]\n",
    "cont02 = [\"incongruent\", \"T\", condition_names, [0, 1]]\n",
    "cont03 = [\"congruent-incongruent\", \"T\", condition_names, [1, -1]]\n",
    "cont04 = [\"incongruent-congruent\", \"T\", condition_names,  [-1, 1]]\n",
    "\n",
    "contrast_list = [\n",
    "    cont01,\n",
    "    cont02,\n",
    "    cont03,\n",
    "    cont04\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR = 2.0  # Repetition Time\n",
    "hpcutoff = 100  # highpass filter cutoff in seconds! \n",
    "\n",
    "modelspec = pe.MapNode(interface=model.SpecifyModel(), name=\"modelspec\", iterfield=[\"subject_info\",\"functional_runs\"])\n",
    "modelspec.inputs.input_units = \"secs\"\n",
    "modelspec.inputs.high_pass_filter_cutoff = hpcutoff\n",
    "modelspec.inputs.time_repetition = TR\n",
    "\n",
    "wf.connect(get_sub_info, 'subject_info', modelspec,'subject_info')\n",
    "wf.connect(highpass, 'out_file',modelspec,'functional_runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "level1design = pe.MapNode(interface=fsl.Level1Design(), name=\"level1design\", iterfield=[\"session_info\"])\n",
    "level1design.inputs.interscan_interval = TR\n",
    "# Set HRF bases functions\n",
    "level1design.inputs.bases = {\"gamma\": {\"derivs\": False, 'gammasigma':3, 'gammadelay':6}}\n",
    "level1design.inputs.model_serial_correlations = True\n",
    "level1design.inputs.contrasts = contrast_list\n",
    "\n",
    "wf.connect(modelspec,'session_info', level1design, 'session_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelgen = pe.MapNode(\n",
    "    interface=fsl.FEATModel(),\n",
    "    name='modelgen',\n",
    "    iterfield=['fsf_file', 'ev_files'])\n",
    "\n",
    "wf.connect([(level1design, modelgen, [('fsf_files', 'fsf_file'), \n",
    "                                    ('ev_files','ev_files')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corresponding fsl command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/film_gls --in=filtered_func_data --rn=stats --pd=design.mat --thr=1000.0 --sa --ms=5 --con=design.con  \n",
    "\n",
    "--thr: threshold\n",
    "--sa: smooth_autocorr\n",
    "--ms: mask_size\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "level1estimate = pe.MapNode(\n",
    "    interface=fsl.FILMGLS(smooth_autocorr=True, mask_size=5, threshold=1000),\n",
    "    name='level1estimate',\n",
    "    iterfield=['design_file', 'in_file', 'tcon_file'])\n",
    "\n",
    "wf.connect([\n",
    "    (highpass,level1estimate,[('out_file','in_file')]),\n",
    "    (modelgen,level1estimate,[('design_file','design_file'),\n",
    "                               ('con_file','tcon_file')])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no need to use `ContrastMgr`, \n",
    "\n",
    "```\n",
    "In interface mode this file assumes that all the required inputs are in the same location. This has deprecated for FSL versions 5.0.7+ as the necessary corrections file is no longer generated by FILMGLS.\n",
    "```\n",
    "see this [link](https://nipype.readthedocs.io/en/latest/api/generated/nipype.interfaces.fsl.model.html#contrastmgr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to [FSL UserGuide](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FEAT/UserGuide#Higher-Level_FEAT_Output), the different sessions need to be **registered** to each other before any multi-session or multi-subject analyses can be carried out. Registration inside FEAT uses `FLIRT` and is a two-statge process:\n",
    "\n",
    "1. An example FMRI low resolution image is registered to an example high resolution image (normally the same subject's T1-weighted structural). The transformation for this is saved into the FEAT directory. Then the high res image is registered to a standard image (normally a T1-weighted image in standard space, such as the MNI 152 average image).\n",
    "2. The two transformations are combined into a third, which will take the low resolution FMRI images (and the statistic images derived from the first-level analyses) straight into standard space, when applied later, during group analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1\n",
    "**Corresponding FSL command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/flirt -in example_func -ref standard -out example_func2standard -omat example_func2standard.mat -cost corratio -dof 12 -searchrx -90 90 -searchry -90 90 -searchrz -90 90 -interp trilinear \n",
    "\n",
    "/usr/local/fsl/bin/convert_xfm -inverse -omat standard2example_func.mat example_func2standard.mat\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt = pe.MapNode(interface=fsl.FLIRT(cost='corratio', dof=12,\n",
    "                                    searchr_x = [-90,90],\n",
    "                                    searchr_y = [-90,90],\n",
    "                                    searchr_z = [-90,90],\n",
    "                                    interp = 'trilinear'), \n",
    "               name='example_func2standard',\n",
    "               iterfield=['in_file'])\n",
    "\n",
    "flt.inputs.reference = fsl.Info.standard_image('MNI152_T1_2mm_brain.nii.gz')\n",
    "wf.connect(extract_ref, 'roi_file', flt, 'in_file')\n",
    "\n",
    "convertxfm = pe.MapNode(interface=fsl.ConvertXFM(invert_xfm = True), \n",
    "                         name='convertxfm',\n",
    "                         iterfield=['in_file'])\n",
    "wf.connect(flt, 'out_matrix_file', convertxfm, 'in_file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2\n",
    "\n",
    "**Corresponding fsl command:**\n",
    "\n",
    "```\n",
    "/usr/local/fsl/bin/flirt -ref reg/standard -in stats/cope1 -out /srv/scratch/yc/fsl/nipype_fsl_comp/gui/sub-01/run1.feat/frgrot_chksugax -applyxfm -init reg/example_func2standard.mat -interp trilinear -datatype float\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_files(copes, varcopes, masks, mat):\n",
    "    # need to reimport here, otherwise errors come out\n",
    "    import nipype.interfaces.fsl as fsl \n",
    "    \n",
    "    out_copes = []\n",
    "    out_varcopes = []\n",
    "    out_masks = []\n",
    "    \n",
    "    # register mask, same function, different parameters\n",
    "    warp_mask = fsl.FLIRT(apply_xfm = True, \n",
    "                     interp = 'nearestneighbour')\n",
    "    warp_mask.inputs.reference = fsl.Info.standard_image('MNI152_T1_2mm_brain.nii.gz')\n",
    "    warp_mask.inputs.in_matrix_file = mat\n",
    "    warp_mask.inputs.output_type = \"NIFTI_GZ\"\n",
    "    warp_mask.inputs.in_file = masks\n",
    "    res_mask = warp_mask.run()\n",
    "    out_masks.append(str(res_mask.outputs.out_file))\n",
    "    \n",
    "    # register copes & varcopes using same function, different parameters\n",
    "    warp = fsl.FLIRT(apply_xfm = True, \n",
    "                     interp = 'trilinear')\n",
    "    warp.inputs.reference = fsl.Info.standard_image('MNI152_T1_2mm_brain.nii.gz')\n",
    "    warp.inputs.in_matrix_file = mat\n",
    "    warp.inputs.output_type = \"NIFTI_GZ\"\n",
    "    \n",
    "    \n",
    "    # register copes\n",
    "    for cope in copes:\n",
    "        warp.inputs.in_file = cope\n",
    "        res = warp.run()\n",
    "        out_copes.append(str(res.outputs.out_file))\n",
    "        \n",
    "     # register varcopes\n",
    "    for varcope in varcopes:\n",
    "        warp.inputs.in_file = varcope\n",
    "        res = warp.run()\n",
    "        out_varcopes.append(str(res.outputs.out_file))\n",
    "\n",
    "    return out_copes, out_varcopes, out_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "warpfunc = pe.MapNode(util.Function(input_names=['copes', 'varcopes', 'masks', 'mat'],\n",
    "                                    output_names=['out_copes', 'out_varcopes', 'out_masks'],\n",
    "                                    function=warp_files),\n",
    "                      iterfield=['copes', 'varcopes', 'masks','mat'],\n",
    "                      name='warpfunc')\n",
    "\n",
    "wf.connect(level1estimate, 'copes', warpfunc, 'copes')\n",
    "wf.connect(level1estimate, 'varcopes', warpfunc, 'varcopes')\n",
    "wf.connect(dilatemask, 'out_file', warpfunc, 'masks')\n",
    "wf.connect(flt, 'out_matrix_file', warpfunc, 'mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all results into one\n",
    "\n",
    "datasink = pe.Node(nio.DataSink(), name='sinker')\n",
    "datasink.inputs.base_directory=os.path.join(exp_dir, \"level1_results\")\n",
    "\n",
    "wf.connect(infosource, 'subject_id', datasink, 'container')\n",
    "wf.connect([(level1estimate, datasink, [('results_dir', 'results_dir')])])\n",
    "wf.connect([(warpfunc, datasink, [('out_copes', 'reg_copes')])])\n",
    "wf.connect([(warpfunc, datasink, [('out_varcopes', 'reg_varcopes')])])\n",
    "wf.connect([(warpfunc, datasink, [('out_masks', 'reg_masks')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1st-level analysis output graph\n",
    "wf.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "\n",
    "# Visualize the graph\n",
    "from IPython.display import Image\n",
    "Image(filename=os.path.join(wf.base_dir, wf.name, 'graph.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220124-00:33:45,769 nipype.workflow INFO:\n",
      "\t Workflow level1 settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "220124-00:33:46,236 nipype.workflow INFO:\n",
      "\t Running in parallel.\n",
      "220124-00:33:46,248 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 26 jobs ready. Free memory (GB): 27.96/27.96, Free processors: 8/8.\n",
      "220124-00:33:46,325 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_26/dg\".\n",
      "220124-00:33:46,332 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_21/dg\".\n",
      "220124-00:33:46,333 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_20/dg\".\n",
      "220124-00:33:46,334 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_19/dg\".\n",
      "220124-00:33:46,340 nipype.workflow INFO:\n",
      "\t [Node] Running \"dg\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220124-00:33:46,345 nipype.workflow INFO:\n",
      "\t [Node] Running \"dg\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220124-00:33:46,345 nipype.workflow INFO:\n",
      "\t [Node] Running \"dg\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220124-00:33:46,346 nipype.workflow INFO:\n",
      "\t [Node] Running \"dg\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220124-00:33:46,358 nipype.workflow INFO:\n",
      "\t [Node] Finished \"level1.dg\".\n",
      "220124-00:33:46,362 nipype.workflow INFO:\n",
      "\t [Node] Finished \"level1.dg\".\n",
      "220124-00:33:46,362 nipype.workflow INFO:\n",
      "\t [Node] Finished \"level1.dg\".\n",
      "220124-00:33:46,366 nipype.workflow INFO:\n",
      "\t [Node] Finished \"level1.dg\".\n",
      "220124-00:33:46,327 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_25/dg\".\n",
      "220124-00:33:46,329 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_23/dg\".\n",
      "220124-00:33:46,380 nipype.workflow INFO:\n",
      "\t [Node] Running \"dg\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220124-00:33:46,328 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_24/dg\".\n",
      "220124-00:33:46,382 nipype.workflow INFO:\n",
      "\t [Node] Running \"dg\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220124-00:33:46,331 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_22/dg\".\n",
      "220124-00:33:46,393 nipype.workflow INFO:\n",
      "\t [Node] Running \"dg\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220124-00:33:46,398 nipype.workflow INFO:\n",
      "\t [Node] Finished \"level1.dg\".\n",
      "220124-00:33:46,398 nipype.workflow INFO:\n",
      "\t [Node] Finished \"level1.dg\".\n",
      "220124-00:33:46,401 nipype.workflow INFO:\n",
      "\t [Node] Running \"dg\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220124-00:33:46,410 nipype.workflow INFO:\n",
      "\t [Node] Finished \"level1.dg\".\n",
      "220124-00:33:46,418 nipype.workflow INFO:\n",
      "\t [Node] Finished \"level1.dg\".\n",
      "220124-00:33:48,249 nipype.workflow INFO:\n",
      "\t [Job 0] Completed (level1.dg).\n",
      "220124-00:33:48,251 nipype.workflow INFO:\n",
      "\t [Job 32] Completed (level1.dg).\n",
      "220124-00:33:48,253 nipype.workflow INFO:\n",
      "\t [Job 64] Completed (level1.dg).\n",
      "220124-00:33:48,254 nipype.workflow INFO:\n",
      "\t [Job 96] Completed (level1.dg).\n",
      "220124-00:33:48,256 nipype.workflow INFO:\n",
      "\t [Job 128] Completed (level1.dg).\n",
      "220124-00:33:48,258 nipype.workflow INFO:\n",
      "\t [Job 160] Completed (level1.dg).\n",
      "220124-00:33:48,259 nipype.workflow INFO:\n",
      "\t [Job 192] Completed (level1.dg).\n",
      "220124-00:33:48,260 nipype.workflow INFO:\n",
      "\t [Job 224] Completed (level1.dg).\n",
      "220124-00:33:48,264 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 34 jobs ready. Free memory (GB): 27.96/27.96, Free processors: 8/8.\n",
      "220124-00:33:48,473 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_18/dg\".\n",
      "220124-00:33:48,473 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_17/dg\".\n",
      "220124-00:33:48,475 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_16/dg\".\n",
      "220124-00:33:48,477 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_14/dg\".\n",
      "220124-00:33:48,476 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_15/dg\".\n",
      "220124-00:33:48,478 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_13/dg\".\n",
      "220124-00:33:48,480 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_12/dg\".\n",
      "220124-00:33:48,481 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_11/dg\".\n",
      "220124-00:33:48,485 nipype.workflow INFO:\n",
      "\t [Node] Running \"dg\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220124-00:33:48,484 nipype.workflow INFO:\n",
      "\t [Node] Running \"dg\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220124-00:33:48,486 nipype.workflow INFO:\n",
      "\t [Node] Running \"dg\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220124-00:33:48,488 nipype.workflow INFO:\n",
      "\t [Node] Running \"dg\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220124-00:33:48,490 nipype.workflow INFO:\n",
      "\t [Node] Running \"dg\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220124-00:33:48,491 nipype.workflow INFO:\n",
      "\t [Node] Running \"dg\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220124-00:33:48,492 nipype.workflow INFO:\n",
      "\t [Node] Running \"dg\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220124-00:33:48,491 nipype.workflow INFO:\n",
      "\t [Node] Running \"dg\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220124-00:33:48,501 nipype.workflow INFO:\n",
      "\t [Node] Finished \"level1.dg\".\n",
      "220124-00:33:48,502 nipype.workflow INFO:\n",
      "\t [Node] Finished \"level1.dg\".\n",
      "220124-00:33:48,504 nipype.workflow INFO:\n",
      "\t [Node] Finished \"level1.dg\".\n",
      "220124-00:33:48,505 nipype.workflow INFO:\n",
      "\t [Node] Finished \"level1.dg\".\n",
      "220124-00:33:48,506 nipype.workflow INFO:\n",
      "\t [Node] Finished \"level1.dg\".\n",
      "220124-00:33:48,507 nipype.workflow INFO:\n",
      "\t [Node] Finished \"level1.dg\".\n",
      "220124-00:33:48,507 nipype.workflow INFO:\n",
      "\t [Node] Finished \"level1.dg\".\n",
      "220124-00:33:48,510 nipype.workflow INFO:\n",
      "\t [Node] Finished \"level1.dg\".\n",
      "220124-00:33:50,251 nipype.workflow INFO:\n",
      "\t [Job 256] Completed (level1.dg).\n",
      "220124-00:33:50,252 nipype.workflow INFO:\n",
      "\t [Job 288] Completed (level1.dg).\n",
      "220124-00:33:50,253 nipype.workflow INFO:\n",
      "\t [Job 320] Completed (level1.dg).\n",
      "220124-00:33:50,255 nipype.workflow INFO:\n",
      "\t [Job 352] Completed (level1.dg).\n",
      "220124-00:33:50,256 nipype.workflow INFO:\n",
      "\t [Job 384] Completed (level1.dg).\n",
      "220124-00:33:50,258 nipype.workflow INFO:\n",
      "\t [Job 416] Completed (level1.dg).\n",
      "220124-00:33:50,259 nipype.workflow INFO:\n",
      "\t [Job 448] Completed (level1.dg).\n",
      "220124-00:33:50,260 nipype.workflow INFO:\n",
      "\t [Job 480] Completed (level1.dg).\n",
      "220124-00:33:50,264 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 58 jobs ready. Free memory (GB): 27.96/27.96, Free processors: 8/8.\n",
      "220124-00:33:50,469 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_10/dg\".\n",
      "220124-00:33:50,470 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_09/dg\".\n",
      "220124-00:33:50,471 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_08/dg\".\n",
      "220124-00:33:50,472 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_07/dg\".\n",
      "220124-00:33:50,475 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_05/dg\".\n",
      "220124-00:33:50,473 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_06/dg\".\n",
      "220124-00:33:50,476 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_04/dg\".\n",
      "220124-00:33:50,477 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"level1.dg\" in \"/home/yc/out/fsl/hw2/level1/_subject_id_03/dg\".\n",
      "220124-00:33:50,481 nipype.workflow INFO:\n",
      "\t [Node] Running \"dg\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220124-00:33:50,482 nipype.workflow INFO:\n",
      "\t [Node] Running \"dg\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220124-00:33:50,485 nipype.workflow INFO:\n",
      "\t [Node] Running \"dg\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220124-00:33:50,484 nipype.workflow INFO:\n",
      "\t [Node] Running \"dg\" (\"nipype.interfaces.io.DataGrabber\")\n"
     ]
    }
   ],
   "source": [
    "# Run Workflow\n",
    "wf.run(plugin=\"MultiProc\", plugin_args={\"n_procs\": 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
